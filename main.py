import json
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

from rcnn_framework import RCNNComparator  # Your own RCNN models comparator
from rcnn_evaluator import ObjectDetectionEvaluator
from optimization_experiments import OptimizationExperiments
from mock_dataset import MockDataset
# 

# Complete demonstration
def run_comprehensive_evaluation():
    """Run the complete evaluation pipeline"""
    print("ğŸš€ Starting Comprehensive RCNN Evaluation Pipeline")
    print("=" * 60)
    
    # Initialize models (using the previously defined comparator)
    from rcnn_framework import RCNNComparator  # Import from previous artifact
    
    comparator = RCNNComparator(num_classes=21)
    models = comparator.models
    
    # Create mock dataset
    test_dataset = MockDataset(size=8)
    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)
    
    # Initialize evaluator
    evaluator = ObjectDetectionEvaluator(models, dataset_name="PASCAL VOC")
    
    # Run comprehensive evaluation
    print("\nğŸ“Š Running Comparative Evaluation...")
    results = evaluator.comparative_evaluation(test_loader)
    
    # Generate detailed report
    print("\nğŸ“‹ Generating Detailed Report...")
    report = evaluator.generate_detailed_report()
    
    # Save report
    with open('comprehensive_evaluation_report.json', 'w') as f:
        json.dump(report, f, indent=2)
    
    # Create visualizations
    print("\nğŸ“ˆ Creating Visualizations...")
    evaluator.visualize_results('rcnn_evaluation_results.png')
    
    # Run optimization experiments
    print("\nğŸ”§ Running Optimization Experiments...")
    optimizer_exp = OptimizationExperiments(models['Faster R-CNN'], test_loader)
    
    # Test different optimizers
    optimizer_configs = {
        'SGD': {'lr': 0.01, 'momentum': 0.9, 'weight_decay': 1e-4},
        'Adam': {'lr': 0.001, 'weight_decay': 1e-4},
        'AdamW': {'lr': 0.001, 'weight_decay': 1e-2},
        'RMSprop': {'lr': 0.0005, 'momentum': 0.9, 'weight_decay': 1e-4}
    }
    optimizer_results = optimizer_exp.experiment_with_optimizers(optimizer_configs)
    print("\nğŸ“ Optimizer Experiment Results:")
    print(json.dumps(optimizer_results, indent=2))

    # Test different learning rates
    lr_results = optimizer_exp.experiment_with_learning_rates(lr_range=(1e-5, 1e-2), num_experiments=4)
    print("\nğŸ“ Learning Rate Experiment Results:")
    print(json.dumps(lr_results, indent=2))

    # Test data augmentation strategies
    augmentation_strategies = {
        'basic': [transforms.RandomHorizontalFlip(), transforms.ToTensor()],
        'color_jitter': [transforms.ColorJitter(brightness=0.2, contrast=0.2), transforms.ToTensor()],
        'random_crop': [transforms.RandomResizedCrop(224), transforms.ToTensor()]
    }
    aug_results = optimizer_exp.experiment_with_data_augmentation(augmentation_strategies)
    print("\nğŸ“ Data Augmentation Experiment Results:")
    print(json.dumps(aug_results, indent=2))

    # Generate optimization report
    print("\nğŸ“‘ Generating Optimization Report...")
    opt_report = optimizer_exp.generate_optimization_report()
    with open('optimization_experiments_report.json', 'w') as f:
        json.dump(opt_report, f, indent=2)
    print("Optimization report saved as optimization_experiments_report.json")

    print("\nâœ… Comprehensive RCNN Evaluation Pipeline Complete!")

if __name__ == "__main__":
    run_comprehensive_evaluation()